{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'scripts/')\n",
    "\n",
    "import resnet50\n",
    "import lasagne\n",
    "import theano\n",
    "import os\n",
    "import skimage.transform\n",
    "import skimage.io\n",
    "import pickle\n",
    "\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download pretrained weights from:\n",
    "# https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/resnet50.pkl\n",
    "model = pickle.load(open('data/resnet50.pkl', 'rb'))\n",
    "classes = model['synset_words']\n",
    "mean_image = model['mean_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat_dog(classes):\n",
    "    cat_classes = [i for i,x in enumerate(classes)\\\n",
    "                   if ' cat' in x\\\n",
    "                   or 'lue point Siamese' in x\\\n",
    "                   or 'tabby, queen' in x\\\n",
    "                   or 'mouser' in x\n",
    "                  ]\n",
    "    dog_classes = [i for i,x in enumerate(classes)\\\n",
    "               if ' dog' in x or ' pointer' in x or 'setter' in x or 'spaniel' in x or 'griffon' in x\\\n",
    "               or 'retriever' in x or 'terrier' in x or 'schnauzer' in x or 'courser' in x\\\n",
    "               or 'hound' in x or 'Weimaraner' in x or 'beagle' in x or 'harrier' in x\\\n",
    "               or 'bluetick' in x or 'redbone' in x or 'rhodesian ridgeback' in x or 'dalmatian' in x\\\n",
    "               or 'ur, mongrel, mutt' in x or 'eist, fice' in x or 'corgi' in x or 'exican hairless' in x\\\n",
    "               or 'poodle' in x or 'asenji' in x or 'eonberg' in x or 'pitz' in x or 'Pomeranian' in x\\\n",
    "               or 'eeshond' in x or 'how, chow chow' in x or 'amoyed, Samoyede' in x or 'reat Pyrenees' in x\\\n",
    "               or 'ekinese, Pekingese, Peke' in x or 'hih-Tzu' in x or 'hihuahua' in x or 'puppy' in x\n",
    "              ]\n",
    "    return cat_classes, dog_classes\n",
    "cat_classes, dog_classes = cat_dog(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computational graph construction\n",
    "net = resnet50.build_model()\n",
    "\n",
    "#load weights\n",
    "lasagne.layers.set_all_param_values(net['prob'], model['values'])\n",
    "\n",
    "#define placeholder variables\n",
    "input_var = T.tensor4('input_var')\n",
    "output_var = lasagne.layers.get_output(net['prob'], {net['input']: input_var}, deterministic=True)\n",
    "\n",
    "#compile prediction function\n",
    "predict_fn = theano.function([input_var], output_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    if len(img.shape) == 2:\n",
    "        return np.array([np.repeat(np.array(img), 3).reshape(3,224,-1)])\n",
    "    return np.array([np.swapaxes(np.swapaxes(img, 0,1), 0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "path = 'data/test/cropped_samples224/'\n",
    "\n",
    "with open('resnet_max.csv', 'a+') as f:\n",
    "    f.write('file,label\\n')\n",
    "i = 0\n",
    "\n",
    "for filename in listdir(path):\n",
    "    img = skimage.io.imread(path+filename)\n",
    "    prob = predict_fn(preprocess(img)).ravel()\n",
    "    cat_proba = np.mean(np.sort(prob[cat_classes])[-3:])\n",
    "    dog_proba = np.mean(np.sort(prob[dog_classes])[-3:])\n",
    "    with open('resnet_max.csv', 'a+') as f:\n",
    "        if cat_proba > dog_proba:\n",
    "            f.write(filename+',cat\\n')\n",
    "        else:\n",
    "            f.write(filename+',dog\\n')\n",
    "\n",
    "    i+=1\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- \n",
    "\n",
    "### Overfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overfeat_classes = np.load('data/overfeat_classes.npy')\n",
    "cat_classes, dog_classes = cat_dog(overfeat_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "path = 'data/test/cropped_samples224/'\n",
    "\n",
    "with open('overfeat_max.csv', 'a+') as f:\n",
    "    f.write('file,label\\n')\n",
    "i = 0\n",
    "\n",
    "for filename in listdir(path):\n",
    "    \n",
    "    res = subprocess.check_output(\" overfeat/bin/macos/overfeat -n 100 -l \"+path+filename,stderr=subprocess.STDOUT,shell=True)\n",
    "    names = []\n",
    "    probas = []\n",
    "    for r in res.split('\\n'):\n",
    "        if len(r) > 0:\n",
    "            parse = r.split(' ')\n",
    "            names.append(' '.join(parse[:-1]))\n",
    "            probas.append(float(parse[-1]))\n",
    "    probas = np.array(probas)\n",
    "    \n",
    "    cats_proba, dogs_proba = cat_dog(names)\n",
    "    cats_proba = np.nan_to_num(np.sum(probas[cats_proba][:3])/3.)\n",
    "    dogs_proba = np.nan_to_num(np.sum(probas[dogs_proba][:3])/3.)\n",
    "    with open('overfeat_max.csv', 'a+') as f:\n",
    "        if cats_proba > dogs_proba:\n",
    "            f.write(filename+',cat\\n')\n",
    "        elif cats_proba < dogs_proba:\n",
    "            f.write(filename+',dog\\n')\n",
    "        elif np.random.rand() > 0.5:\n",
    "            f.write(filename+',cat\\n')\n",
    "        else:\n",
    "            f.write(filename+',dog\\n')\n",
    "\n",
    "    i+=1\n",
    "    if i % 10 == 0:\n",
    "        print i,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-----\n",
    "\n",
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copyright: see http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_3'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_3'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_3'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(\n",
    "        net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net\n",
    "\n",
    "net = build_model()\n",
    "with open('data/vgg16.pkl') as f:\n",
    "    weights = pickle.load(f)\n",
    "lasagne.layers.set_all_param_values(net[\"prob\"],weights['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "output = lasagne.layers.get_output(net['prob'], input_image,deterministic=True)\n",
    "predict_fn = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = pickle.load(open('vgg_classes.pkl'))\n",
    "cat_classes, dog_classes = cat_dog(classes)\n",
    "\n",
    "path = 'data/test/cropped_samples224/'\n",
    "\n",
    "with open('vgg_max.csv', 'a+') as f:\n",
    "    f.write('file,label\\n')\n",
    "i = 0\n",
    "\n",
    "for filename in listdir(path):\n",
    "    img = skimage.io.imread(path+filename)\n",
    "    prob = predict_fn(preprocess(img)).ravel()\n",
    "    cat_proba = np.mean(np.sort(prob[cat_classes])[-3:])\n",
    "    dog_proba = np.mean(np.sort(prob[dog_classes])[-3:])\n",
    "    with open('vgg_max.csv', 'a+') as f:\n",
    "        if cat_proba > dog_proba:\n",
    "            f.write(filename+',cat\\n')\n",
    "        else:\n",
    "            f.write(filename+',dog\\n')\n",
    "\n",
    "    i+=1\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
