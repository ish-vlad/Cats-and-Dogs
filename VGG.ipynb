{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time \n",
    "import sys\n",
    "import xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/train/vgg_train_features.csv', header=None, index_col=0)\n",
    "y = np.array([0 if x.startswith('cat') else 1 for x in X.index])\n",
    "X_test = pd.read_csv('data/test/vgg_test_features.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((22000, 4096), (22000,))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>4096</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dog.1619.jpg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.973565</td>\n",
       "      <td>5.215432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.926491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog.9505.jpg</th>\n",
       "      <td>0.604877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.768252</td>\n",
       "      <td>0.966774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.409990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat.9425.jpg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.233131</td>\n",
       "      <td>0.296057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880284</td>\n",
       "      <td>1.727552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.213197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat.4447.jpg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.242090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.208019</td>\n",
       "      <td>2.630467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.954571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat.762.jpg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.309701</td>\n",
       "      <td>3.420354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.157184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.259615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.783026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3         4     5         6     \\\n",
       "0                                                                      \n",
       "dog.1619.jpg  0.000000  2.973565  5.215432  0.000000   0.0  0.000000   \n",
       "dog.9505.jpg  0.604877  0.000000  2.768252  0.966774   0.0  0.000000   \n",
       "cat.9425.jpg  0.000000  0.000000  0.000000  0.000000   0.0  1.233131   \n",
       "cat.4447.jpg  0.000000  0.000000  0.000000  7.242090   0.0  0.000000   \n",
       "cat.762.jpg   0.000000  0.000000  2.309701  3.420354   0.0  0.000000   \n",
       "\n",
       "                  7     8         9         10      ...     4087      4088  \\\n",
       "0                                                   ...                      \n",
       "dog.1619.jpg  0.000000   0.0  0.000000  0.000000    ...      0.0  0.000000   \n",
       "dog.9505.jpg  6.409990   0.0  0.000000  0.000000    ...      0.0  2.104954   \n",
       "cat.9425.jpg  0.296057   0.0  0.000000  1.609659    ...      0.0  0.000000   \n",
       "cat.4447.jpg  0.000000   0.0  0.039648  0.000000    ...      0.0  0.000000   \n",
       "cat.762.jpg   2.157184   0.0  0.000000  0.000000    ...      0.0  0.000000   \n",
       "\n",
       "              4089  4090      4091      4092      4093      4094  4095  \\\n",
       "0                                                                        \n",
       "dog.1619.jpg   0.0   0.0  0.000000  0.944644  0.000000  2.926491   0.0   \n",
       "dog.9505.jpg   0.0   0.0  0.000000  0.000000  0.000000  0.000000   0.0   \n",
       "cat.9425.jpg   0.0   0.0  0.880284  1.727552  0.000000  0.000000   0.0   \n",
       "cat.4447.jpg   0.0   0.0  0.000000  5.208019  2.630467  0.000000   0.0   \n",
       "cat.762.jpg    0.0   0.0  1.259615  0.000000  0.000000  0.000000   0.0   \n",
       "\n",
       "                  4096  \n",
       "0                       \n",
       "dog.1619.jpg  0.000000  \n",
       "dog.9505.jpg  0.000000  \n",
       "cat.9425.jpg  2.213197  \n",
       "cat.4447.jpg  1.954571  \n",
       "cat.762.jpg   1.783026  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=3000)\n",
    "print(X_train.shape, y_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=4)]: Done 190 out of 190 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=190, n_jobs=4, oob_score=False, random_state=None,\n",
       "            verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetuned\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=190,\n",
    "    max_depth=None,\n",
    "    warm_start=True,\n",
    "    n_jobs=4, verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.9693\n",
      "Precition:\t0.9657\n",
      "Recall:\t\t0.9734\n",
      "F1-score:\t0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 190 out of 190 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "print('Accuracy:\\t%.4f' % accuracy_score(y_val, y_pred))\n",
    "print('Precition:\\t%.4f' % precision_score(y_val, y_pred))\n",
    "print('Recall:\\t\\t%.4f' % recall_score(y_val, y_pred))\n",
    "print('F1-score:\\t%.4f' % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFyCAYAAACpypMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqVFgISIiIqlRYCEiIiKpUWAhIiIiqfl/FjOuFFUbRekAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104420290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.feature_importances_)\n",
    "plt.xlim((0, X.shape[1]))\n",
    "plt.title('Feature importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(clf.predict(X_test), columns=['label'], index=X_test.index)\n",
    "y_pred[y_pred['label'] == 0] = 'cat'\n",
    "y_pred[y_pred['label'] == 1] = 'dog'\n",
    "y_pred.to_csv('vgg_rf.csv', index_label='file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.65, average=False, class_weight=None, epsilon=1.0,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=4,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetuned\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', epsilon=1., alpha=0.65,  n_jobs=4)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.9763\n",
      "Precition:\t0.9767\n",
      "Recall:\t\t0.9761\n",
      "F1-score:\t0.9764\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "print('Accuracy:\\t%.4f' % accuracy_score(y_val, y_pred))\n",
    "print('Precition:\\t%.4f' % precision_score(y_val, y_pred))\n",
    "print('Recall:\\t\\t%.4f' % recall_score(y_val, y_pred))\n",
    "print('F1-score:\\t%.4f' % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(clf.predict(X_test), columns=['label'], index=X_test.index)\n",
    "y_pred[y_pred['label'] == 0] = 'cat'\n",
    "y_pred[y_pred['label'] == 1] = 'dog'\n",
    "y_pred.to_csv('vgg_sgd.csv', index_label='file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import BatchNormLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax, sigmoid\n",
    "\n",
    "# finetuned\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 4096))\n",
    "    net['fc1'] = DenseLayer(net['input'], num_units=512, nonlinearity=None)\n",
    "    net['bn1'] = BatchNormLayer(net['fc1'])\n",
    "    net['nl1'] = NonlinearityLayer(net['bn1'], sigmoid)\n",
    "    net['fc1_dropout'] = DropoutLayer(net['nl1'], p=0.5)\n",
    "    net['fc2'] = DenseLayer(net['fc1_dropout'], num_units=64, nonlinearity=None)\n",
    "    net['bn2'] = BatchNormLayer(net['fc2'])\n",
    "    net['nl2'] = NonlinearityLayer(net['bn2'], sigmoid)\n",
    "    net['fc2_dropout'] = DropoutLayer(net['nl2'], p=0.5)\n",
    "    net['fc3'] = DenseLayer(net['fc2_dropout'], num_units=2, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc3'], softmax)\n",
    "\n",
    "    return net\n",
    "\n",
    "# batch generator\n",
    "def get_batches(dataset, batch_size):\n",
    "    X, Y = dataset\n",
    "    n_samples = X.shape[0]\n",
    "        \n",
    "    # Shuffle at the start of epoch\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_idx = indices[start:end]\n",
    "    \n",
    "        yield X.loc[X.index[batch_idx]], Y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.matrix('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "learning_rate = T.scalar(name='learning_rate')\n",
    "\n",
    "net = build_model()\n",
    "\n",
    "prediction = lasagne.layers.get_output(net['prob'], input_var)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var).mean()\n",
    "\n",
    "params = lasagne.layers.get_all_params(net['prob'], trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = lasagne.layers.get_output(net['prob'], input_var, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var).mean()\n",
    "\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var, learning_rate], loss, updates=updates, allow_input_downcast=True)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc], allow_input_downcast=True)\n",
    "predict = theano.function([input_var], test_prediction, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 of 70 took 14.650s\n",
      "  loss:\t\t\t0.495189,0.213263\n",
      "  validation accuracy:\t\t95.23 %\n",
      "\n",
      "Epoch 2 of 70 took 14.249s\n",
      "  loss:\t\t\t0.323056,0.189897\n",
      "  validation accuracy:\t\t96.23 %\n",
      "\n",
      "Epoch 3 of 70 took 16.048s\n",
      "  loss:\t\t\t0.275076,0.175937\n",
      "  validation accuracy:\t\t96.87 %\n",
      "\n",
      "Epoch 4 of 70 took 17.490s\n",
      "  loss:\t\t\t0.251369,0.165233\n",
      "  validation accuracy:\t\t96.97 %\n",
      "\n",
      "Epoch 5 of 70 took 17.074s\n",
      "  loss:\t\t\t0.235663,0.156210\n",
      "  validation accuracy:\t\t97.30 %\n",
      "\n",
      "Epoch 6 of 70 took 13.535s\n",
      "  loss:\t\t\t0.220313,0.149320\n",
      "  validation accuracy:\t\t97.23 %\n",
      "\n",
      "Epoch 7 of 70 took 16.510s\n",
      "  loss:\t\t\t0.211799,0.143165\n",
      "  validation accuracy:\t\t97.27 %\n",
      "\n",
      "Epoch 8 of 70 took 15.509s\n",
      "  loss:\t\t\t0.204222,0.138039\n",
      "  validation accuracy:\t\t97.37 %\n",
      "\n",
      "Epoch 9 of 70 took 15.334s\n",
      "  loss:\t\t\t0.194345,0.133163\n",
      "  validation accuracy:\t\t97.30 %\n",
      "\n",
      "Epoch 10 of 70 took 13.025s\n",
      "  loss:\t\t\t0.188562,0.128811\n",
      "  validation accuracy:\t\t97.37 %\n",
      "\n",
      "Epoch 11 of 70 took 15.015s\n",
      "  loss:\t\t\t0.184346,0.124692\n",
      "  validation accuracy:\t\t97.40 %\n",
      "\n",
      "Epoch 12 of 70 took 13.635s\n",
      "  loss:\t\t\t0.174839,0.121728\n",
      "  validation accuracy:\t\t97.37 %\n",
      "\n",
      "Epoch 13 of 70 took 16.321s\n",
      "  loss:\t\t\t0.168428,0.118080\n",
      "  validation accuracy:\t\t97.37 %\n",
      "\n",
      "Epoch 14 of 70 took 17.384s\n",
      "  loss:\t\t\t0.167082,0.114624\n",
      "  validation accuracy:\t\t97.43 %\n",
      "\n",
      "Epoch 15 of 70 took 11.964s\n",
      "  loss:\t\t\t0.161700,0.111516\n",
      "  validation accuracy:\t\t97.40 %\n",
      "\n",
      "Epoch 16 of 70 took 14.124s\n",
      "  loss:\t\t\t0.158776,0.108673\n",
      "  validation accuracy:\t\t97.57 %\n",
      "\n",
      "Epoch 17 of 70 took 12.898s\n",
      "  loss:\t\t\t0.152846,0.106090\n",
      "  validation accuracy:\t\t97.67 %\n",
      "\n",
      "Epoch 18 of 70 took 12.264s\n",
      "  loss:\t\t\t0.151579,0.103962\n",
      "  validation accuracy:\t\t97.67 %\n",
      "\n",
      "Epoch 19 of 70 took 12.249s\n",
      "  loss:\t\t\t0.145117,0.101849\n",
      "  validation accuracy:\t\t97.63 %\n",
      "\n",
      "Epoch 20 of 70 took 12.988s\n",
      "  loss:\t\t\t0.144076,0.099852\n",
      "  validation accuracy:\t\t97.60 %\n",
      "\n",
      "Epoch 21 of 70 took 15.674s\n",
      "  loss:\t\t\t0.137850,0.097800\n",
      "  validation accuracy:\t\t97.57 %\n",
      "\n",
      "Epoch 22 of 70 took 14.797s\n",
      "  loss:\t\t\t0.136211,0.094996\n",
      "  validation accuracy:\t\t97.57 %\n",
      "\n",
      "Epoch 23 of 70 took 18.786s\n",
      "  loss:\t\t\t0.131835,0.094025\n",
      "  validation accuracy:\t\t97.57 %\n",
      "\n",
      "Epoch 24 of 70 took 12.939s\n",
      "  loss:\t\t\t0.132562,0.092713\n",
      "  validation accuracy:\t\t97.63 %\n",
      "\n",
      "Epoch 25 of 70 took 16.936s\n",
      "  loss:\t\t\t0.130486,0.090502\n",
      "  validation accuracy:\t\t97.67 %\n",
      "\n",
      "Epoch 26 of 70 took 12.429s\n",
      "  loss:\t\t\t0.123622,0.088806\n",
      "  validation accuracy:\t\t97.67 %\n",
      "\n",
      "Epoch 27 of 70 took 12.170s\n",
      "  loss:\t\t\t0.122399,0.087692\n",
      "  validation accuracy:\t\t97.77 %\n",
      "\n",
      "Epoch 28 of 70 took 12.515s\n",
      "  loss:\t\t\t0.120903,0.086169\n",
      "  validation accuracy:\t\t97.73 %\n",
      "\n",
      "Epoch 29 of 70 took 13.452s\n",
      "  loss:\t\t\t0.117233,0.084629\n",
      "  validation accuracy:\t\t97.70 %\n",
      "\n",
      "Epoch 30 of 70 took 14.390s\n",
      "  loss:\t\t\t0.114800,0.083683\n",
      "  validation accuracy:\t\t97.73 %\n",
      "\n",
      "Epoch 31 of 70 took 12.223s\n",
      "  loss:\t\t\t0.113928,0.082129\n",
      "  validation accuracy:\t\t97.77 %\n",
      "\n",
      "Epoch 32 of 70 took 12.848s\n",
      "  loss:\t\t\t0.110538,0.081069\n",
      "  validation accuracy:\t\t97.73 %\n",
      "\n",
      "Epoch 33 of 70 took 12.947s\n",
      "  loss:\t\t\t0.110034,0.080983\n",
      "  validation accuracy:\t\t97.77 %\n",
      "\n",
      "Epoch 34 of 70 took 13.731s\n",
      "  loss:\t\t\t0.106536,0.079748\n",
      "  validation accuracy:\t\t97.73 %\n",
      "\n",
      "Epoch 35 of 70 took 12.486s\n",
      "  loss:\t\t\t0.105312,0.079347\n",
      "  validation accuracy:\t\t97.73 %\n",
      "\n",
      "Epoch 36 of 70 took 15.146s\n",
      "  loss:\t\t\t0.105296,0.078024\n",
      "  validation accuracy:\t\t97.80 %\n",
      "\n",
      "Epoch 37 of 70 took 14.302s\n",
      "  loss:\t\t\t0.104826,0.076669\n",
      "  validation accuracy:\t\t97.73 %\n",
      "\n",
      "Epoch 38 of 70 took 16.385s\n",
      "  loss:\t\t\t0.098495,0.076860\n",
      "  validation accuracy:\t\t97.73 %\n",
      "\n",
      "Epoch 39 of 70 took 15.101s\n",
      "  loss:\t\t\t0.100357,0.075683\n",
      "  validation accuracy:\t\t97.77 %\n",
      "\n",
      "Epoch 40 of 70 took 13.375s\n",
      "  loss:\t\t\t0.096035,0.075858\n",
      "  validation accuracy:\t\t97.67 %\n",
      "\n",
      "Epoch 41 of 70 took 13.511s\n",
      "  loss:\t\t\t0.095636,0.074045\n",
      "  validation accuracy:\t\t97.70 %\n",
      "\n",
      "Epoch 42 of 70 took 16.651s\n",
      "  loss:\t\t\t0.092655,0.073902\n",
      "  validation accuracy:\t\t97.77 %\n",
      "\n",
      "Epoch 43 of 70 took 16.840s\n",
      "  loss:\t\t\t0.092510,0.073126\n",
      "  validation accuracy:\t\t97.63 %\n",
      "\n",
      "Epoch 44 of 70 took 14.242s\n",
      "  loss:\t\t\t0.090868,0.072758\n",
      "  validation accuracy:\t\t97.60 %\n",
      "\n",
      "Epoch 45 of 70 took 18.956s\n",
      "  loss:\t\t\t0.089616,0.072418\n",
      "  validation accuracy:\t\t97.60 %\n",
      "\n",
      "Epoch 46 of 70 took 14.669s\n",
      "  loss:\t\t\t0.085844,0.071076\n",
      "  validation accuracy:\t\t97.70 %\n",
      "\n",
      "Epoch 47 of 70 took 15.851s\n",
      "  loss:\t\t\t0.086567,0.071182\n",
      "  validation accuracy:\t\t97.57 %\n",
      "\n",
      "Epoch 48 of 70 took 14.919s\n",
      "  loss:\t\t\t0.082703,0.071324\n",
      "  validation accuracy:\t\t97.50 %\n",
      "\n",
      "Epoch 49 of 70 took 11.197s\n",
      "  loss:\t\t\t0.084047,0.070564\n",
      "  validation accuracy:\t\t97.60 %\n",
      "\n",
      "Epoch 50 of 70 took 11.906s\n",
      "  loss:\t\t\t0.082885,0.070081\n",
      "  validation accuracy:\t\t97.53 %\n",
      "\n",
      "Epoch 51 of 70 took 14.802s\n",
      "  loss:\t\t\t0.080944,0.069598\n",
      "  validation accuracy:\t\t97.63 %\n",
      "\n",
      "Epoch 52 of 70 took 11.685s\n",
      "  loss:\t\t\t0.079947,0.069301\n",
      "  validation accuracy:\t\t97.50 %\n",
      "\n",
      "Epoch 53 of 70 took 11.910s\n",
      "  loss:\t\t\t0.079139,0.069935\n",
      "  validation accuracy:\t\t97.60 %\n",
      "\n",
      "Epoch 54 of 70 took 13.581s\n",
      "  loss:\t\t\t0.078914,0.068953\n",
      "  validation accuracy:\t\t97.47 %\n",
      "\n",
      "Epoch 55 of 70 took 15.783s\n",
      "  loss:\t\t\t0.076995,0.067884\n",
      "  validation accuracy:\t\t97.50 %\n",
      "\n",
      "Epoch 56 of 70 took 12.655s\n",
      "  loss:\t\t\t0.074032,0.068710\n",
      "  validation accuracy:\t\t97.50 %\n",
      "\n",
      "Epoch 57 of 70 took 12.326s\n",
      "  loss:\t\t\t0.076259,0.067769\n",
      "  validation accuracy:\t\t97.67 %\n",
      "\n",
      "Epoch 58 of 70 took 13.152s\n",
      "  loss:\t\t\t0.074223,0.068150\n",
      "  validation accuracy:\t\t97.53 %\n",
      "\n",
      "Epoch 59 of 70 took 18.004s\n",
      "  loss:\t\t\t0.072285,0.068807\n",
      "  validation accuracy:\t\t97.60 %\n",
      "\n",
      "Epoch 60 of 70 took 12.657s\n",
      "  loss:\t\t\t0.074975,0.067872\n",
      "  validation accuracy:\t\t97.50 %\n",
      "\n",
      "Epoch 61 of 70 took 14.261s\n",
      "  loss:\t\t\t0.068727,0.066872\n",
      "  validation accuracy:\t\t97.57 %\n",
      "\n",
      "Epoch 62 of 70 took 12.115s\n",
      "  loss:\t\t\t0.071636,0.067797\n",
      "  validation accuracy:\t\t97.63 %\n",
      "\n",
      "Epoch 63 of 70 took 12.704s\n",
      "  loss:\t\t\t0.068594,0.066716\n",
      "  validation accuracy:\t\t97.77 %\n",
      "\n",
      "Epoch 64 of 70 took 13.729s\n",
      "  loss:\t\t\t0.066645,0.067238\n",
      "  validation accuracy:\t\t97.60 %\n",
      "\n",
      "Epoch 65 of 70 took 14.533s\n",
      "  loss:\t\t\t0.065830,0.066451\n",
      "  validation accuracy:\t\t97.67 %\n",
      "\n",
      "Epoch 66 of 70 took 11.087s\n",
      "  loss:\t\t\t0.066179,0.066970\n",
      "  validation accuracy:\t\t97.53 %\n",
      "\n",
      "Epoch 67 of 70 took 10.968s\n",
      "  loss:\t\t\t0.065651,0.067309\n",
      "  validation accuracy:\t\t97.63 %\n",
      "\n",
      "Epoch 68 of 70 took 11.440s\n",
      "  loss:\t\t\t0.064049,0.065495\n",
      "  validation accuracy:\t\t97.53 %\n",
      "\n",
      "Epoch 69 of 70 took 14.789s\n",
      "  loss:\t\t\t0.064021,0.065608\n",
      "  validation accuracy:\t\t97.63 %\n",
      "\n",
      "Epoch 70 of 70 took 12.100s\n",
      "  loss:\t\t\t0.061481,0.066879\n",
      "  validation accuracy:\t\t97.70 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 70\n",
    "lr = 1e-4\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in get_batches((X_train, y_train), 1000):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets, lr)\n",
    "        train_batches += 1\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in get_batches((X_val, y_val), 500):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "#     # Then we print the results for this epoch:\n",
    "#     if epoch % 5 == 0: \n",
    "    print(\"\\nEpoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  loss:\\t\\t\\t{:.6f},{:.6f}\".format(train_err / train_batches, val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9950 0.9956 0.9943 0.9949\n",
      "Valid: 0.9770 0.9838 0.9701 0.9769\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "for batch in get_batches((X_train, y_train), 500):\n",
    "    inputs, targets = batch\n",
    "    y_pred.extend((predict(inputs)[:,1] > 0.5).astype(int))\n",
    "    y_true.extend(targets)\n",
    "print('Train: %.4f %.4f %.4f %.4f' %\\\n",
    "      (accuracy_score(y_true, y_pred),\\\n",
    "       precision_score(y_true, y_pred),\\\n",
    "       recall_score(y_true, y_pred),\\\n",
    "       f1_score(y_true, y_pred)))\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for batch in get_batches((X_val, y_val), 500):\n",
    "    inputs, targets = batch\n",
    "    y_pred.extend((predict(inputs)[:,1] > 0.5).astype(int))\n",
    "    y_true.extend(targets)\n",
    "    \n",
    "print('Valid: %.4f %.4f %.4f %.4f' %\\\n",
    "      (accuracy_score(y_true, y_pred),\\\n",
    "       precision_score(y_true, y_pred),\\\n",
    "       recall_score(y_true, y_pred),\\\n",
    "       f1_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(predict(X_test)[:,1] > 0.5, columns=['label'], index=X_test.index)\n",
    "y_pred[y_pred['label'] == False] = 'cat'\n",
    "y_pred[y_pred['label'] == True] = 'dog'\n",
    "y_pred.to_csv('vgg_nn.csv', index_label='file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bytree=0.5, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=5, n_estimators=200, nthread=4,\n",
       "       objective='binary:logistic', seed=0, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetuned\n",
    "clf = xgboost.XGBClassifier(\n",
    "        max_depth=5, \n",
    "        min_child_weight=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree = 0.5,\n",
    "        n_estimators=200,\n",
    "        objective='binary:logistic', nthread=4)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.9763\n",
      "Precition:\t0.9793\n",
      "Recall:\t\t0.9734\n",
      "F1-score:\t0.9764\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "print('Accuracy:\\t%.4f' % accuracy_score(y_val, y_pred))\n",
    "print('Precition:\\t%.4f' % precision_score(y_val, y_pred))\n",
    "print('Recall:\\t\\t%.4f' % recall_score(y_val, y_pred))\n",
    "print('F1-score:\\t%.4f' % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(clf.predict(X_test), columns=['label'], index=X_test.index)\n",
    "y_pred[y_pred['label'] == 0] = 'cat'\n",
    "y_pred[y_pred['label'] == 1] = 'dog'\n",
    "y_pred.to_csv('vgg_xgbst.csv', index_label='file')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
